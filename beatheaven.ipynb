{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7954867,"sourceType":"datasetVersion","datasetId":4678633},{"sourceId":8032844,"sourceType":"datasetVersion","datasetId":4658446}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport math\nimport random\nimport bisect\nimport shutil\nimport PIL\nimport gc\n\nimport librosa\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torchvision\nimport torchvision.transforms as T\nimport torchaudio\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm.notebook import tqdm\nfrom collections import OrderedDict\nfrom multiprocessing import Pool\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:18:51.084086Z","iopub.execute_input":"2024-04-12T22:18:51.084400Z","iopub.status.idle":"2024-04-12T22:19:00.176981Z","shell.execute_reply.started":"2024-04-12T22:18:51.084370Z","shell.execute_reply":"2024-04-12T22:19:00.176135Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class func_pbar:\n    def __init__(self, target_iters, pbar=None):\n        from functools import wraps\n        from inspect import isawaitable\n        self.wr = wraps\n        self.is_async = isawaitable\n        self.target_iters = target_iters\n        self.first_call = True\n        self.pbar_func = pbar\n\n    def init_pbar(self):\n        if not self.pbar_func:\n            from tqdm import tqdm\n            self.pbar = tqdm(total=self.target_iters, leave=False)\n        else:\n            self.pbar = self.pbar_func(total=self.target_iters, leave=False)\n    \n    def __call__(self, fn):\n        @self.wr(fn)\n        async def async_wrapper(*args, **kwargs):\n            if self.first_call:\n                self.first_call = False\n                self.init_pbar()\n            result = await fn(*args, **kwargs)\n            self.pbar.update(1)\n            return result\n        \n        @self.wr(fn)\n        def wrapper(*args, **kwargs):\n            if self.first_call:\n                self.first_call = False\n                self.init_pbar()\n            result = fn(*args, **kwargs)\n            self.pbar.update(1)\n            return result\n        \n        if self.is_async(fn):\n            return async_wrapper\n        else:\n            return wrapper","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.178556Z","iopub.execute_input":"2024-04-12T22:19:00.178954Z","iopub.status.idle":"2024-04-12T22:19:00.189149Z","shell.execute_reply.started":"2024-04-12T22:19:00.178929Z","shell.execute_reply":"2024-04-12T22:19:00.188063Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def fix_dataset(path, new_path):\n    music_downloaded = os.listdir(path)\n    fixed = list(map(lambda x: x[:-3]+'wav', music_downloaded))\n    shutil.copytree(path, new_path)\n    [os.rename(new_path+'/'+src, new_path+'/'+dst) for src, dst in zip(music_downloaded, fixed)]","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.194561Z","iopub.execute_input":"2024-04-12T22:19:00.194859Z","iopub.status.idle":"2024-04-12T22:19:00.201731Z","shell.execute_reply.started":"2024-04-12T22:19:00.194837Z","shell.execute_reply":"2024-04-12T22:19:00.200753Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class BasicModule(nn.Module):\n    def __init__(self):\n        super(BasicModule, self).__init__()\n        self.model_name = str(type(self))\n\n    def load(self, path):\n        self.load_state_dict(torch.load(path))\n\n    def save(self, name=None):\n        prefix = 'check_points/' + self.model_name +name+ '/'\n        if not os.path.isdir(prefix):\n            os.mkdir(prefix)\n        name = time.strftime(prefix + '%m%d_%H:%M:%S.pth')\n        print('model name', name.split('/')[-1] )\n        torch.save(self.state_dict(), name)\n        torch.save(self.state_dict(), prefix+'latest.pth')\n        return name\n    \n    def get_optimizer(self, lr, weight_decay):\n        return torch.optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n    \n    def load_latest(self, notes):\n        path = 'check_points/' + self.model_name +notes+ '/latest.pth'\n        self.load_state_dict(torch.load(path))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.202779Z","iopub.execute_input":"2024-04-12T22:19:00.203064Z","iopub.status.idle":"2024-04-12T22:19:00.216925Z","shell.execute_reply.started":"2024-04-12T22:19:00.203041Z","shell.execute_reply":"2024-04-12T22:19:00.216021Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CQTNet(BasicModule):\n    def __init__(self, emb_size=300):\n        super().__init__()\n        self.emb_size = emb_size\n        self.features = nn.Sequential(OrderedDict([\n            ('conv0', nn.Conv2d(1, 32, kernel_size=(12, 3), dilation=(1, 1), padding=(6, 0), bias=False)),\n            ('norm0', nn.BatchNorm2d(32)), ('relu0', nn.ReLU(inplace=True)),\n            ('conv1', nn.Conv2d(32, 64, kernel_size=(13, 3), dilation=(1, 2), bias=False)),\n            ('norm1', nn.BatchNorm2d(64)), ('relu1', nn.ReLU(inplace=True)),\n            ('pool1', nn.MaxPool2d((1, 2), stride=(1, 2), padding=(0, 1))),\n\n            ('conv2', nn.Conv2d(64, 64, kernel_size=(13, 3), dilation=(1, 1), bias=False)),\n            ('norm2', nn.BatchNorm2d(64)), ('relu2', nn.ReLU(inplace=True)),\n            ('conv3', nn.Conv2d(64, 64, kernel_size=(3, 3), dilation=(1, 2), bias=False)),\n            ('norm3', nn.BatchNorm2d(64)), ('relu3', nn.ReLU(inplace=True)),\n            ('pool3', nn.MaxPool2d((1, 2), stride=(1, 2), padding=(0, 1))),\n\n            ('conv4', nn.Conv2d(64, 128, kernel_size=(3, 3), dilation=(1, 1), bias=False)),\n            ('norm4', nn.BatchNorm2d(128)), ('relu4', nn.ReLU(inplace=True)),\n            ('conv5', nn.Conv2d(128, 128, kernel_size=(3, 3), dilation=(1, 2), bias=False)),\n            ('norm5', nn.BatchNorm2d(128)), ('relu5', nn.ReLU(inplace=True)),\n            ('pool5', nn.MaxPool2d((1, 2), stride=(1, 2), padding=(0, 1))),\n\n            ('conv6', nn.Conv2d(128, 256, kernel_size=(3, 3), dilation=(1, 1), bias=False)),\n            ('norm6', nn.BatchNorm2d(256)), ('relu6', nn.ReLU(inplace=True)),\n            ('conv7', nn.Conv2d(256, 256, kernel_size=(3, 3), dilation=(1, 2), bias=False)),\n            ('norm7', nn.BatchNorm2d(256)), ('relu7', nn.ReLU(inplace=True)),\n            ('pool7', nn.MaxPool2d((1, 2), stride=(1, 2), padding=(0, 1))),\n\n            ('conv8', nn.Conv2d(256, 512, kernel_size=(3, 3), dilation=(1, 1), bias=False)),\n            ('norm8', nn.BatchNorm2d(512)), ('relu8', nn.ReLU(inplace=True)),\n            ('conv9', nn.Conv2d(512, 512, kernel_size=(3, 3), dilation=(1, 2), bias=False)),\n            ('norm9', nn.BatchNorm2d(512)), ('relu9', nn.ReLU(inplace=True)),\n        ]))\n        self.pool = nn.AdaptiveMaxPool2d((1, 1))\n        self.fc0 = nn.Linear(512, emb_size)\n\n    def forward(self, song1, samples1=None, song2=None, samples2=None):\n        inputs = list(filter(lambda x: x is not None, [song1, samples1, song2, samples2]))\n        outputs = []\n        for x in inputs:\n            shape = x.shape\n            if len(shape) == 3:\n                x = x.view(1, *shape)\n            elif len(shape) == 5:\n                x = x.view(-1, *shape[2:])\n            N = x.size()[0]\n            x = self.features(x)  # [N, 512, 57, 2~15]\n            x = self.pool(x)\n            x = x.view(N, -1)\n            feature = self.fc0(x)\n            if len(shape) == 5:\n                feature = feature.view(*shape[:2], -1)\n            outputs.append(feature)\n        return tuple(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.218327Z","iopub.execute_input":"2024-04-12T22:19:00.218583Z","iopub.status.idle":"2024-04-12T22:19:00.241550Z","shell.execute_reply.started":"2024-04-12T22:19:00.218562Z","shell.execute_reply":"2024-04-12T22:19:00.240738Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"music_path = '/kaggle/input/last-fm-us-music/music'\ndata_path = '/kaggle/input/last-fm-us-music-data/music_data'\n#fixed_path = '/kaggle/music'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.242764Z","iopub.execute_input":"2024-04-12T22:19:00.243034Z","iopub.status.idle":"2024-04-12T22:19:00.255140Z","shell.execute_reply.started":"2024-04-12T22:19:00.243012Z","shell.execute_reply":"2024-04-12T22:19:00.254440Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#fix_dataset(music_path, fixed_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.256237Z","iopub.execute_input":"2024-04-12T22:19:00.256555Z","iopub.status.idle":"2024-04-12T22:19:00.266276Z","shell.execute_reply.started":"2024-04-12T22:19:00.256525Z","shell.execute_reply":"2024-04-12T22:19:00.265514Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#@func_pbar(len(os.listdir(new_path)), tqdm)\ndef preprocess(filename: str, new_filename: str, cqt_time_reduction=20) -> None:\n    song, sr = librosa.load(filename)\n    cqt = np.abs(librosa.cqt(y=song, sr=sr))\n    height, length = cqt.shape\n    cqt_compressed = cqt[:, :(length//cqt_time_reduction)*cqt_time_reduction].reshape(height, -1, cqt_time_reduction).mean(axis=2)\n    np.save(new_filename, cqt_compressed)\n\ndef preprocess_path(path: str, out_path: str, cqt_time_reduction = 20, threads: int = 1) -> None:\n    file_list = os.listdir(path)\n    new_file_list = list(map(lambda x: out_path + '/' * int(out_path[-1] != '/') + x[:x.rfind('.')] + '.npy', file_list))\n    file_list = list(map(lambda x: path + '/' * int(path[-1] != '/') + x, file_list))\n    os.makedirs(out_path, exist_ok=True)\n    pbar = func_pbar(len(file_list), pbar=tqdm)\n    if threads == 1:\n        for file, new_file in zip(file_list, new_file_list):\\\n            pbar(preprocess)(file, new_file, cqt_time_reduction)\n            #preprocess(file, new_file, cqt_time_reduction)\n    elif threads < 1:\n        raise ValueError(\"Threads must be a positive integer\")\n    else:\n        pool = Pool(threads)\n        #pool.starmap(pbar(preprocess), list(zip(file_list, new_file_list, [cqt_time_reduction]*len(file_list))))\n        pool.starmap(preprocess, list(zip(file_list, new_file_list, [cqt_time_reduction]*len(file_list))))\n        pool.close()\n        pool.join()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.267287Z","iopub.execute_input":"2024-04-12T22:19:00.267542Z","iopub.status.idle":"2024-04-12T22:19:00.277989Z","shell.execute_reply.started":"2024-04-12T22:19:00.267520Z","shell.execute_reply":"2024-04-12T22:19:00.277015Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def cut_data(data, out_length, pad_to=None):\n    if out_length is not None:\n        if data.shape[0] > out_length:\n            max_offset = data.shape[0] - out_length\n            offset = np.random.randint(max_offset)\n            data = data[offset:(out_length+offset),:]\n        else:\n            offset = out_length - data.shape[0]\n            data = np.pad(data, ((0,offset),(0,0)), \"constant\")\n    if data.shape[0] < 200:\n        offset = 200 - data.shape[0]\n        data = np.pad(data, ((0,offset),(0,0)), \"constant\")\n        \n    if pad_to:\n        data = np.pad(data, ((0,pad_to-data.shape[0]),(0,0)), \"constant\")\n        \n    return data\n\ndef cut_data_front(data, out_length):\n    if out_length is not None:\n        if data.shape[0] > out_length:\n            max_offset = data.shape[0] - out_length\n            offset = 0\n            data = data[offset:(out_length+offset),:]\n        else:\n            offset = out_length - data.shape[0]\n            data = np.pad(data, ((0,offset),(0,0)), \"constant\")\n    if data.shape[0] < 200:\n        offset = 200 - data.shape[0]\n        data = np.pad(data, ((0,offset),(0,0)), \"constant\")\n    return data\n\ndef shorter(feature, mean_size=2):\n    length, height  = feature.shape\n    new_f = np.zeros((int(length/mean_size),height),dtype=np.float64)\n    for i in range(int(length/mean_size)):\n        new_f[i,:] = feature[i*mean_size:(i+1)*mean_size,:].mean(axis=0)\n    return new_f\n\ndef change_speed(data, l=0.7, r=1.5): # change data.shape[0]\n    new_len = int(data.shape[0]*np.random.uniform(l,r))\n    maxx = np.max(data)+1\n    data0 = PIL.Image.fromarray((data*255.0/maxx).astype(np.uint8))\n    transform = transforms.Compose([\n        transforms.Resize(size=(new_len,data.shape[1])), \n    ])\n    new_data = transform(data0)\n    return np.array(new_data)/255.0*maxx\n\ndef SpecAugment(data):\n    F = 24\n    f = np.random.randint(F)\n    f0 = np.random.randint(84-f)\n    data[f0:f0+f,:]*=0\n    return data\n\nclass CQT(Dataset):\n    def __init__(self, file_list, mode='train', out_length=None, n_samples=1):\n        #self.data_path = data_path\n        self.mode = mode\n        self.file_list = file_list\n        #self.file_list = list(map(lambda x: data_path + '/' * int(data_path[-1] != '/') + x, os.listdir(data_path)))\n        self.out_length = out_length\n        self.n_samples = n_samples\n        self.transforms = {\n            'train_song': T.Compose([\n                lambda x : x.T,\n                lambda x : x.astype(np.float32) / (np.max(np.abs(x))+ 1e-6),\n                lambda x : cut_data(x, self.out_length),\n                lambda x : torch.Tensor(x),\n                lambda x : x.permute(1,0).unsqueeze(0),\n            ]),\n            'train_sample': T.Compose([\n                lambda x : x.T,\n                lambda x : x.astype(np.float32) / (np.max(np.abs(x))+ 1e-6),\n                lambda x : cut_data(x, np.random.randint(10, self.out_length), self.out_length),\n                lambda x : torch.Tensor(x),\n                lambda x : x.permute(1,0).unsqueeze(0),\n            ])\n        }\n        \n    def __getitem__(self, index):\n        index2 = np.random.choice(np.concatenate([np.arange(index), np.arange(index + 1, len(self.file_list))]))\n        songs, samples = [], []\n        for i, index in enumerate((index, index2)):\n            filename = self.file_list[index]\n            data = np.load(filename)\n            songs.append(self.transforms['train_song'](data))\n            samples.append([])\n            for j in range(self.n_samples):\n                samples[i].append(self.transforms['train_sample'](data))\n            samples[i] = torch.stack(samples[i])\n        return (songs[0], samples[0], songs[1], samples[1], index)\n    \n    def __len__(self):\n        return len(self.file_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.283314Z","iopub.execute_input":"2024-04-12T22:19:00.283657Z","iopub.status.idle":"2024-04-12T22:19:00.311860Z","shell.execute_reply.started":"2024-04-12T22:19:00.283634Z","shell.execute_reply":"2024-04-12T22:19:00.310653Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/data/'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.313250Z","iopub.execute_input":"2024-04-12T22:19:00.313663Z","iopub.status.idle":"2024-04-12T22:19:00.324782Z","shell.execute_reply.started":"2024-04-12T22:19:00.313630Z","shell.execute_reply":"2024-04-12T22:19:00.323797Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#preprocess_path(music_path, data_dir, threads=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.326334Z","iopub.execute_input":"2024-04-12T22:19:00.326757Z","iopub.status.idle":"2024-04-12T22:19:00.335578Z","shell.execute_reply.started":"2024-04-12T22:19:00.326727Z","shell.execute_reply":"2024-04-12T22:19:00.334585Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#!zip -r data.zip /kaggle/data","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.337057Z","iopub.execute_input":"2024-04-12T22:19:00.337636Z","iopub.status.idle":"2024-04-12T22:19:00.344427Z","shell.execute_reply.started":"2024-04-12T22:19:00.337604Z","shell.execute_reply":"2024-04-12T22:19:00.343291Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#shutil.rmtree(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.346108Z","iopub.execute_input":"2024-04-12T22:19:00.346701Z","iopub.status.idle":"2024-04-12T22:19:00.354263Z","shell.execute_reply.started":"2024-04-12T22:19:00.346665Z","shell.execute_reply":"2024-04-12T22:19:00.353507Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloaders, n_epochs, criterion, metric, optimizer, scheduler=None, device='cpu', backup_freq=None, init_epoch=0):\n    model.to(device)\n    print('Computing datasets')\n    with torch.no_grad():\n        for phase in tqdm(('train', 'val')):\n            datasets[phase] = torch.zeros((len(dataloaders[phase].dataset), model.module.emb_size)).to(device)\n            for item in tqdm(dataloaders[phase]):\n                dataloaders[item[2]] = model(item[0].to(device))[0].detach()\n    print('Training')\n    for epoch in tqdm(range(init_epoch, n_epochs)):\n        print(f'Epoch {epoch+1}')\n        for phase in ('train', 'val'):\n            mean_loss = 0\n            mean_loss_pos_neg = 0\n            mean_accuracy = 0\n            num_iters = 0\n            \n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            for batch in tqdm(dataloaders[phase]):\n                song1, samples1, song2, samples2, index = tuple(map(lambda x: x.to(device), batch))\n                \n                if phase == 'train':\n                    song1_emb, samples1_emb, song2_emb, samples2_emb = model(song1, samples1, song2, samples2)\n                else:\n                    with torch.no_grad():\n                        song1_emb, samples1_emb, song2_emb, samples2_emb = model(song1, samples1, song2, samples2)\n                \n                loss = criterion(song1_emb, samples1_emb, song2_emb, samples2_emb)\n                \n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                    \n                datasets[phase][index, :] = song1_emb\n                mean_accuracy += metric(samples1_emb, datasets[phase], index)\n                mean_loss += loss\n                mean_loss_pos_neg += loss_pos_neg_fixed(song1_emb, samples1_emb, song2_emb, samples2_emb)\n                num_iters += 1\n            print(f'{phase} loss: {mean_loss/num_iters}')\n            print(f'{phase} loss positive: {mean_loss_pos_neg[0]/num_iters}')\n            print(f'{phase} loss negative: {mean_loss_pos_neg[1]/num_iters}')\n            print(f'{phase} accuracy: {mean_accuracy/num_iters}')\n        \n        if scheduler:\n            if type(scheduler) == torch.optim.lr_scheduler.ReduceLROnPlateau:\n                scheduler.step(mean_loss/num_iters)\n            else:\n                scheduler.step()\n        \n        if backup_freq:\n            if (epoch+1) % backup_freq == 0:\n                serializer.backup(model, f'model_ep{epoch+1}.pth')\n                \n        del song1, samples1, song2, samples2, song1_emb, samples1_emb, song2_emb, samples2_emb, index, loss, mean_loss, mean_loss_pos_neg, mean_accuracy, num_iters\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.355598Z","iopub.execute_input":"2024-04-12T22:19:00.355853Z","iopub.status.idle":"2024-04-12T22:19:00.371898Z","shell.execute_reply.started":"2024-04-12T22:19:00.355831Z","shell.execute_reply":"2024-04-12T22:19:00.370928Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(data_path))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.372833Z","iopub.execute_input":"2024-04-12T22:19:00.373125Z","iopub.status.idle":"2024-04-12T22:19:00.466899Z","shell.execute_reply.started":"2024-04-12T22:19:00.373102Z","shell.execute_reply":"2024-04-12T22:19:00.465985Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"6341"},"metadata":{}}]},{"cell_type":"code","source":"file_list = list(map(lambda x: data_path + '/' * int(data_path[-1] != '/') + x, os.listdir(data_path)))","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.468236Z","iopub.execute_input":"2024-04-12T22:19:00.468839Z","iopub.status.idle":"2024-04-12T22:19:00.481194Z","shell.execute_reply.started":"2024-04-12T22:19:00.468806Z","shell.execute_reply":"2024-04-12T22:19:00.480385Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"files_train, files_test = train_test_split(\n    file_list,\n    test_size=0.2,\n    random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.482233Z","iopub.execute_input":"2024-04-12T22:19:00.482581Z","iopub.status.idle":"2024-04-12T22:19:00.490667Z","shell.execute_reply.started":"2024-04-12T22:19:00.482547Z","shell.execute_reply":"2024-04-12T22:19:00.489695Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def triplet_loss(song1=None, samples1=None, song2=None, samples2=None, positive_rate=0.5):\n    def loss_fn(song1, samples1=None, song2=None, samples2=None):\n        loss = 0\n        if samples1 is not None and song2 is not None and samples2 is not None:\n            norm_coef = 1 / (song1.shape[0] * samples1.shape[1] * (samples1.shape[1] + 1))\n            loss += (torch.pairwise_distance(song1[:, None, :], samples1).sum() +\n                     torch.pairwise_distance(samples1[:, :, None, :], samples1[:, None, :, :]).sum() / 2 +\n                     torch.pairwise_distance(song2[:, None, :], samples2).sum() +\n                     torch.pairwise_distance(samples2[:, :, None, :], samples2[:, None, :, :]).sum() / 2)\\\n                    * positive_rate * norm_coef\n            norm_coef =  song1.shape[0] * (samples1.shape[1] + 1) ** 2\n            loss += 1 / (torch.pairwise_distance(song1, song2).sum() +\n                         torch.pairwise_distance(samples1, samples2).sum() +\n                         torch.pairwise_distance(song1[:, None, :], samples2).sum() +\n                         torch.pairwise_distance(song1[:, None, :], samples2).sum())\\\n                    * (1 - positive_rate) * norm_coef\n        return loss\n    if song1 is None and samples1 is None and song2 is None and samples2 is None:\n        return loss_fn\n    return loss_fn(song1, samples1, song2, samples2)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.491828Z","iopub.execute_input":"2024-04-12T22:19:00.492121Z","iopub.status.idle":"2024-04-12T22:19:00.504090Z","shell.execute_reply.started":"2024-04-12T22:19:00.492097Z","shell.execute_reply":"2024-04-12T22:19:00.503220Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def triplet_loss_fixed(song1=None, samples1=None, song2=None, samples2=None, positive_rate=0.5):\n    def loss_fn(song1, samples1=None, song2=None, samples2=None):\n        loss = 0\n        if samples1 is not None and song2 is not None and samples2 is not None:\n            norm_coef = 1 / 2\n            loss += (torch.pairwise_distance(song1[:, None, :], samples1).mean() +\n                     torch.pairwise_distance(song2[:, None, :], samples2).mean())\\\n                    * positive_rate * norm_coef\n            loss += 1 / torch.pairwise_distance(song1, song2).mean()\\\n                    * (1 - positive_rate)\n        return loss\n    if song1 is None and samples1 is None and song2 is None and samples2 is None:\n        return loss_fn\n    return loss_fn(song1, samples1, song2, samples2)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.505289Z","iopub.execute_input":"2024-04-12T22:19:00.505639Z","iopub.status.idle":"2024-04-12T22:19:00.519806Z","shell.execute_reply.started":"2024-04-12T22:19:00.505616Z","shell.execute_reply":"2024-04-12T22:19:00.519007Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def triplet_loss_fixed(song1=None, samples1=None, song2=None, samples2=None, positive_rate=0.5):\n    def loss_fn(song1, samples1=None, song2=None, samples2=None):\n        loss = 0\n        if samples1 is not None and song2 is not None and samples2 is not None:\n            norm_coef = 1\n            loss += torch.pairwise_distance(song1[:, None, :], samples1).mean()\\\n                    * positive_rate * norm_coef\n            loss += 1 / torch.pairwise_distance(song1, song2).mean()\\\n                    * (1 - positive_rate)\n        return loss\n    if song1 is None and samples1 is None and song2 is None and samples2 is None:\n        return loss_fn\n    return loss_fn(song1, samples1, song2, samples2)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:43:15.016301Z","iopub.execute_input":"2024-04-12T22:43:15.017119Z","iopub.status.idle":"2024-04-12T22:43:15.024121Z","shell.execute_reply.started":"2024-04-12T22:43:15.017084Z","shell.execute_reply":"2024-04-12T22:43:15.023137Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def loss_pos_neg(song1, samples1, song2, samples2):\n    loss = torch.zeros((2))\n    norm_coef = 1 / (song1.shape[0] * samples1.shape[1] * (samples1.shape[1] + 1))\n    loss[0] = (torch.pairwise_distance(song1[:, None, :], samples1).sum() +\n             torch.pairwise_distance(samples1[:, :, None, :], samples1[:, None, :, :]).sum() / 2 +\n             torch.pairwise_distance(song2[:, None, :], samples2).sum() +\n             torch.pairwise_distance(samples2[:, :, None, :], samples2[:, None, :, :]).sum() / 2)\\\n            * norm_coef\n    norm_coef = song1.shape[0] * (samples1.shape[1] + 1) ** 2\n    loss[1] = 1 / (torch.pairwise_distance(song1, song2).sum() +\n                 torch.pairwise_distance(samples1, samples2).sum() +\n                 torch.pairwise_distance(song1[:, None, :], samples2).sum() +\n                 torch.pairwise_distance(song1[:, None, :], samples2).sum())\\\n            * norm_coef\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.521028Z","iopub.execute_input":"2024-04-12T22:19:00.521578Z","iopub.status.idle":"2024-04-12T22:19:00.534848Z","shell.execute_reply.started":"2024-04-12T22:19:00.521548Z","shell.execute_reply":"2024-04-12T22:19:00.534091Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def loss_pos_neg_fixed(song1, samples1, song2, samples2):\n    loss = torch.zeros((2))\n    norm_coef = 1 / 2\n    loss[0] = (torch.pairwise_distance(song1[:, None, :], samples1).mean() +\n             torch.pairwise_distance(song2[:, None, :], samples2).mean())\\\n            * norm_coef\n    loss[1] = 1 / torch.pairwise_distance(song1, song2).mean()\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.535793Z","iopub.execute_input":"2024-04-12T22:19:00.536072Z","iopub.status.idle":"2024-04-12T22:19:00.544593Z","shell.execute_reply.started":"2024-04-12T22:19:00.536037Z","shell.execute_reply":"2024-04-12T22:19:00.543843Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def accuracy(batch, all_data, batch_indices):\n    batch = batch[:, 0, :].view(batch.shape[0], -1)\n    indices = torch.pairwise_distance(batch[:, None, :], all_data[None, :, :]).min(dim=-1).indices\n    accuracy = torch.mean((batch_indices == indices).type(torch.FloatTensor))\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.545587Z","iopub.execute_input":"2024-04-12T22:19:00.545816Z","iopub.status.idle":"2024-04-12T22:19:00.557793Z","shell.execute_reply.started":"2024-04-12T22:19:00.545796Z","shell.execute_reply":"2024-04-12T22:19:00.556990Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"n_gpus = torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.558815Z","iopub.execute_input":"2024-04-12T22:19:00.559095Z","iopub.status.idle":"2024-04-12T22:19:00.593751Z","shell.execute_reply.started":"2024-04-12T22:19:00.559073Z","shell.execute_reply":"2024-04-12T22:19:00.593083Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"datasets = {\n    'train': CQT(files_train, mode='train', out_length=394, n_samples=2),\n    'val': CQT(files_test, mode='val', out_length=394, n_samples=2)\n}\ndataloaders = {\n    'train': DataLoader(datasets['train'], batch_size=24 * n_gpus),\n    'val': DataLoader(datasets['val'], batch_size=24 * n_gpus)\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.594641Z","iopub.execute_input":"2024-04-12T22:19:00.594877Z","iopub.status.idle":"2024-04-12T22:19:00.601853Z","shell.execute_reply.started":"2024-04-12T22:19:00.594850Z","shell.execute_reply":"2024-04-12T22:19:00.600891Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.602927Z","iopub.execute_input":"2024-04-12T22:19:00.603208Z","iopub.status.idle":"2024-04-12T22:19:00.656385Z","shell.execute_reply.started":"2024-04-12T22:19:00.603187Z","shell.execute_reply":"2024-04-12T22:19:00.655503Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = CQTNet(300).to(device)\nif n_gpus > 1:\n    model = torch.nn.parallel.DataParallel(model, device_ids=list(range(n_gpus)), dim=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.657641Z","iopub.execute_input":"2024-04-12T22:19:00.658022Z","iopub.status.idle":"2024-04-12T22:19:00.927759Z","shell.execute_reply.started":"2024-04-12T22:19:00.657994Z","shell.execute_reply":"2024-04-12T22:19:00.926945Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5], gamma=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:19:00.931844Z","iopub.execute_input":"2024-04-12T22:19:00.932145Z","iopub.status.idle":"2024-04-12T22:19:00.936908Z","shell.execute_reply.started":"2024-04-12T22:19:00.932119Z","shell.execute_reply":"2024-04-12T22:19:00.936007Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train(model, dataloaders, 10, triplet_loss_fixed(positive_rate=0.5), accuracy, optimizer, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-04-12T22:43:26.700117Z","iopub.execute_input":"2024-04-12T22:43:26.700844Z","iopub.status.idle":"2024-04-12T22:43:59.520172Z","shell.execute_reply.started":"2024-04-12T22:43:26.700812Z","shell.execute_reply":"2024-04-12T22:43:59.518555Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Computing datasets\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6e3dfc54354d559bc7d016dc392fa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/106 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ea0841df33241d997807b894ebe00fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/27 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc1418132b8e4ca0858dcd4eb4eb9861"}},"metadata":{}},{"name":"stdout","text":"Training\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbbda885c6c142bf965bcc9ec85f735a"}},"metadata":{}},{"name":"stdout","text":"Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/106 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa5eb99f4c2e45288afbad6be1081f11"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriplet_loss_fixed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[14], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloaders, n_epochs, criterion, metric, optimizer, scheduler, device, backup_freq, init_epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m song1, samples1, song2, samples2, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mto(device), batch))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     song1_emb, samples1_emb, song2_emb, samples2_emb \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msong1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msong2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:110\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    108\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 110\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/3828923816.py\", line 48, in forward\n    x = self.features(x)  # [N, 512, 57, 2~15]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n    return F.max_pool2d(input, self.kernel_size, self.stride,\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py\", line 488, in fn\n    return if_false(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 11.06 MiB is free. Process 3042 has 14.73 GiB memory in use. Of the allocated memory 14.01 GiB is allocated by PyTorch, and 513.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"],"ename":"OutOfMemoryError","evalue":"Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/3828923816.py\", line 48, in forward\n    x = self.features(x)  # [N, 512, 57, 2~15]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n    return F.max_pool2d(input, self.kernel_size, self.stride,\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py\", line 488, in fn\n    return if_false(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 11.06 MiB is free. Process 3042 has 14.73 GiB memory in use. Of the allocated memory 14.01 GiB is allocated by PyTorch, and 513.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"error"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:51:56.276887Z","iopub.execute_input":"2024-04-09T19:51:56.277139Z","iopub.status.idle":"2024-04-09T19:51:56.510129Z","shell.execute_reply.started":"2024-04-09T19:51:56.277117Z","shell.execute_reply":"2024-04-09T19:51:56.509221Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}